"""
X-Ray Mike - å­¸è¡“ç´šé€è¦–åœ–åƒè™•ç†æ¨¡å‹
æ”¯æŒå¤šç¨®é€è¦–æ¨¡å¼å’Œåœ–åƒå¢å¼·ç®—æ³•
"""

import torch
import numpy as np
from PIL import Image
import cv2
from typing import Optional
from cog import BasePredictor, Input, Path
import io
import tempfile


class Predictor(BasePredictor):
    """X-Ray Mike é æ¸¬å™¨"""

    def setup(self):
        """åŠ è¼‰æ¨¡å‹å’Œåˆå§‹åŒ–ï¼ˆå¦‚æœéœ€è¦é è¨“ç·´æ¬Šé‡ï¼‰"""
        print("âœ… X-Ray Mike åˆå§‹åŒ–å®Œæˆ")
        # å¦‚æœæœ‰é è¨“ç·´æ¨¡å‹æ¬Šé‡ï¼Œåœ¨é€™è£¡åŠ è¼‰
        # self.model = torch.load("weights.pth")

    def predict(
        self,
        image: Path = Input(description="è¼¸å…¥åœ–ç‰‡"),
        mode: str = Input(
            description="é€è¦–æ¨¡å¼",
            default="clahe",
            choices=["neutral", "clahe", "retinex", "adaptive", "wavelet", "gradient"]
        ),
        intensity: float = Input(
            description="é€è¦–å¼·åº¦ (0-10)",
            default=4.5,
            ge=0,
            le=10
        ),
        sharpen: float = Input(
            description="éŠ³åŒ–å¼·åº¦ (0-3)",
            default=1.0,
            ge=0,
            le=3
        ),
        edge: float = Input(
            description="é‚Šç·£å¢å¼· (0-1)",
            default=0.4,
            ge=0,
            le=1
        ),
        contrast: float = Input(
            description="å°æ¯”åº¦èª¿æ•´ (0.5-2.0)",
            default=1.0,
            ge=0.5,
            le=2.0
        ),
    ) -> Path:
        """
        åŸ·è¡Œ X-ray é€è¦–è™•ç†

        Args:
            image: è¼¸å…¥åœ–ç‰‡è·¯å¾‘
            mode: é€è¦–æ¨¡å¼
            intensity: é€è¦–å¼·åº¦
            sharpen: éŠ³åŒ–å¼·åº¦
            edge: é‚Šç·£å¢å¼·
            contrast: å°æ¯”åº¦

        Returns:
            è™•ç†å¾Œçš„åœ–ç‰‡è·¯å¾‘
        """

        print(f"ğŸ” é–‹å§‹è™•ç†åœ–ç‰‡ - æ¨¡å¼: {mode}, å¼·åº¦: {intensity}")

        # 1. è®€å–åœ–ç‰‡
        img = Image.open(image).convert('RGB')
        img_array = np.array(img)

        # 2. è½‰æ›åˆ°é©åˆè™•ç†çš„æ ¼å¼
        img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        img_processed = img_array.copy()

        # 3. æ ¹æ“šæ¨¡å¼æ‡‰ç”¨ä¸åŒçš„é€è¦–ç®—æ³•
        if mode == "clahe":
            img_processed = self._apply_clahe(img_gray, intensity)
        elif mode == "retinex":
            img_processed = self._apply_retinex(img_array, intensity)
        elif mode == "adaptive":
            img_processed = self._apply_adaptive(img_gray, intensity)
        elif mode == "wavelet":
            img_processed = self._apply_wavelet(img_array, intensity)
        elif mode == "gradient":
            img_processed = self._apply_gradient(img_gray, intensity)
        else:  # neutral
            img_processed = self._apply_neutral(img_gray, intensity)

        # 4. æ‡‰ç”¨éŠ³åŒ–
        if sharpen > 0:
            img_processed = self._apply_sharpen(img_processed, sharpen)

        # 5. æ‡‰ç”¨é‚Šç·£å¢å¼·
        if edge > 0:
            img_processed = self._apply_edge(img_processed, edge)

        # 6. æ‡‰ç”¨å°æ¯”åº¦èª¿æ•´
        if contrast != 1.0:
            img_processed = self._apply_contrast(img_processed, contrast)

        # 7. ç¢ºä¿æ•¸å€¼ç¯„åœæ­£ç¢º
        img_processed = np.clip(img_processed, 0, 255).astype(np.uint8)

        # 8. ä¿å­˜çµæœ
        output_path = Path(tempfile.mktemp(suffix=".png"))
        result_img = Image.fromarray(img_processed)
        result_img.save(output_path, format='PNG', quality=95)

        print(f"âœ… è™•ç†å®Œæˆ: {output_path}")

        return output_path

    def _apply_clahe(self, img_gray: np.ndarray, intensity: float) -> np.ndarray:
        """CLAHE (å°æ¯”åº¦é™åˆ¶è‡ªé©æ‡‰ç›´æ–¹åœ–å‡è¡¡åŒ–)"""
        clip_limit = 2.0 + intensity * 0.5
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))
        img_clahe = clahe.apply(img_gray)
        return cv2.cvtColor(img_clahe, cv2.COLOR_GRAY2RGB)

    def _apply_retinex(self, img: np.ndarray, intensity: float) -> np.ndarray:
        """Retinex MSR (å¤šå°ºåº¦ Retinex)"""
        img_float = img.astype(np.float32) + 1.0

        # å¤šå°ºåº¦
        scales = [15, 80, 250]
        msr = np.zeros_like(img_float)

        for scale in scales:
            blur = cv2.GaussianBlur(img_float, (0, 0), scale)
            msr += np.log10(img_float) - np.log10(blur)

        msr = msr / len(scales)
        msr = msr * intensity * 10

        # æ­¸ä¸€åŒ–
        msr = cv2.normalize(msr, None, 0, 255, cv2.NORM_MINMAX)
        return msr.astype(np.uint8)

    def _apply_adaptive(self, img_gray: np.ndarray, intensity: float) -> np.ndarray:
        """è‡ªé©æ‡‰å¢å¼·"""
        block_size = int(31 + intensity * 10)
        if block_size % 2 == 0:
            block_size += 1

        img_adaptive = cv2.adaptiveThreshold(
            img_gray, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY,
            block_size, 2
        )

        # åè½‰ä¸¦æ··åˆ
        img_inv = 255 - img_adaptive
        alpha = min(intensity / 10, 0.8)
        img_blend = cv2.addWeighted(img_gray, 1 - alpha, img_inv, alpha, 0)

        return cv2.cvtColor(img_blend, cv2.COLOR_GRAY2RGB)

    def _apply_wavelet(self, img: np.ndarray, intensity: float) -> np.ndarray:
        """å°æ³¢è®Šæ›å¢å¼·ï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
        # ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯é‡‘å­—å¡”æ¨¡æ“¬å°æ³¢æ•ˆæœ
        gaussian = cv2.GaussianBlur(img, (5, 5), 0)
        laplacian = cv2.subtract(img, gaussian)

        # å¢å¼·é«˜é »ç´°ç¯€
        enhanced = cv2.addWeighted(img, 1.0, laplacian, intensity * 0.5, 0)
        return enhanced

    def _apply_gradient(self, img_gray: np.ndarray, intensity: float) -> np.ndarray:
        """æ¢¯åº¦ç†±åœ–"""
        # Sobel æ¢¯åº¦
        grad_x = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)

        # è¨ˆç®—æ¢¯åº¦å¹…åº¦
        magnitude = np.sqrt(grad_x**2 + grad_y**2)
        magnitude = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)
        magnitude = magnitude.astype(np.uint8)

        # æ‡‰ç”¨ç†±åœ–
        heatmap = cv2.applyColorMap(magnitude, cv2.COLORMAP_JET)

        # æ··åˆåŸåœ–
        alpha = min(intensity / 10, 0.7)
        img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)
        blended = cv2.addWeighted(img_rgb, 1 - alpha, heatmap, alpha, 0)

        return blended

    def _apply_neutral(self, img_gray: np.ndarray, intensity: float) -> np.ndarray:
        """æ¨™æº–é€è¦–å¢å¼·"""
        # åŸºç¤å°æ¯”åº¦å¢å¼·
        enhanced = cv2.convertScaleAbs(img_gray, alpha=1 + intensity * 0.1, beta=0)
        return cv2.cvtColor(enhanced, cv2.COLOR_GRAY2RGB)

    def _apply_sharpen(self, img: np.ndarray, strength: float) -> np.ndarray:
        """éŠ³åŒ–"""
        kernel = np.array([
            [0, -1, 0],
            [-1, 5 + strength, -1],
            [0, -1, 0]
        ])
        return cv2.filter2D(img, -1, kernel)

    def _apply_edge(self, img: np.ndarray, strength: float) -> np.ndarray:
        """é‚Šç·£å¢å¼·"""
        if len(img.shape) == 3:
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        else:
            gray = img

        edges = cv2.Canny(gray, 50, 150)
        edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)

        return cv2.addWeighted(img, 1.0, edges_rgb, strength * 0.3, 0)

    def _apply_contrast(self, img: np.ndarray, contrast: float) -> np.ndarray:
        """å°æ¯”åº¦èª¿æ•´"""
        return cv2.convertScaleAbs(img, alpha=contrast, beta=0)
